{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "556156e5",
   "metadata": {},
   "source": [
    "<!-- LTeX: language=fr -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a6e592",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cours 2 : Modèles de langues à n-grammes\n",
    "========================================\n",
    "\n",
    "**Loïc Grobol** [<lgrobol@parisnanterre.fr>](mailto:lgrobol@parisnanterre.fr)\n",
    "\n",
    "2022-09-28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6f6c4ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1779bad8",
   "metadata": {},
   "source": [
    "## Modèles de langues\n",
    "\n",
    "Qu'est-ce que vous pensez des phrases suivantes ?\n",
    "\n",
    "> Bonjour, ça va ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca61f5da",
   "metadata": {},
   "source": [
    "> Je reconnais l'existence du kiwi-fruit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f804d8",
   "metadata": {},
   "source": [
    "> Les idées vertes incolores dorment furieusement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059ffcea",
   "metadata": {},
   "source": [
    "> Vous désastre réjouirez de que ce aucun."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b1b07a",
   "metadata": {},
   "source": [
    "> oijj eofiz ipjij paihefoîozenui."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97af65db",
   "metadata": {},
   "source": [
    "Est-ce qu'il y en a qui vous parlent plus que d'autres ? Pourquoi ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187d57d",
   "metadata": {},
   "source": [
    "Pour plein de raisons, étant donné un langage (et une variété de ce langage, etc.), il y a des\n",
    "phrases qu'on risque de voir ou d'entendre plus souvent que d'autres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03941cf9",
   "metadata": {},
   "source": [
    "On peut dire ainsi que certaines phrases sont plus **vraisemblables** que d'autres."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b60ee",
   "metadata": {},
   "source": [
    "On peut y penser de la manière suivante (pour l'instant) :\n",
    "\n",
    "- On prend toutes les phrases qui ont été un jour prononcées dans cette langue.\n",
    "- On les écrit toutes (avec répétition) sur des bouts de papiers.\n",
    "- On met les bouts de papier dans une urne géante, on touille et on en choisit un."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10897c1c",
   "metadata": {},
   "source": [
    "On peut alors parler de *probabilité* d'avoir choisi une phrase donnée. Et se demander :\n",
    "\n",
    "> Si j'ai une phrase, par exemple « Toi dont le trône étincelle, ô immortelle Aphrodite. », comment\n",
    "> estimer cette probabilité ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35f15a9",
   "metadata": {},
   "source": [
    "Un modèle de langue, c'est un **modèle** qui permet d'**estimer** la **vraisemblance** d'une\n",
    "**phrase**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c67d486",
   "metadata": {},
   "source": [
    "Notre objectif aujourd'hui c'est de voir comment on fait ça, d'abord en théorie, puis en pratique\n",
    "sur une application marrante et très très très à la mode : la génération de textes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5260bca",
   "metadata": {},
   "source": [
    "À quoi ça sert ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fea2786",
   "metadata": {},
   "source": [
    "À plein de trucs\n",
    "\n",
    "- Traduction automatique :\n",
    "  - $P(\\text{moche temps pour la saison}) > P(\\text{sale temps pour la saison})$\n",
    "- Correction orthographique :\n",
    "  - Je ne peux pas **croitre** cette histoire\n",
    "  - $P(\\text{peux pas croire cette}) > P(\\text{peux pas croitre cette})$\n",
    "- Reconnaissance de la parole (ASR)\n",
    "  - $P(\\text{Par les temps qui courent}) >> P(\\text{Parle et t'en qui cours})$\n",
    "- Résumé automatique, questions/réponses…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2125bce1",
   "metadata": {},
   "source": [
    "On se basera pour la théorie et les notations sur le chapitre 3 de [*Speech and Language\n",
    "Processing*](https://web.stanford.edu/~jurafsky/slp3/) de Daniel Jurafsky et James H. Martin. À ta\n",
    "place, je le garderais donc à portée de main, le poly *et* les slides."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2d458",
   "metadata": {},
   "source": [
    "## Formalisons (un peu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27868030",
   "metadata": {},
   "source": [
    "On veut assigner des probabilités (≈) à des séquences de mots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fbf266",
   "metadata": {},
   "source": [
    "Si on note une séquence de mots $S = w_1, w_2, …, w_n$, on notera sa probabilité $P( w_1, w_2, …,\n",
    "w_n)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000a8580",
   "metadata": {},
   "source": [
    "### Estimateur du maximum de vraisemblance\n",
    "\n",
    "Rappel : on peut estimer la probabilité d'un truc en calculant sa fréquence d'apparition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcc68a9",
   "metadata": {},
   "source": [
    "Par exemple, si on veut estimer la probabilité qu'un dé truqué fasse 6 :\n",
    "\n",
    "- On lance le dé un grand nombre de fois (mettons qu'on choisisse 1000), on parle d'**échantillon**.\n",
    "- On compte le nombre de fois qu'on a obtenu 6, imaginons que c'est 271.\n",
    "- On calcule la **fréquence d'apparition** de 6 : \\frac{271}{1000} = 0.271.\n",
    "- On **choisit** cette valeur comme estimation de la probabilité d'avoir 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e765c8",
   "metadata": {},
   "source": [
    "Notez que c'est bien une estimation, et qu'elle n'est pas infaillible. On peut obtenir 1000 fois 6\n",
    "de suite, même avec un dé équilibré. C'est improbable, mais ça peut arriver, et dans ce cas notre\n",
    "estimation de la probabilité sera affreusement fausse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4f0d53",
   "metadata": {},
   "source": [
    "Cette façon d'estimer une probabilité c'est (un cas particulier de) l'**estimateur du maximum de\n",
    "vraisemblance**. La façon la plus simple d'estimer des probabilités."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c6c855",
   "metadata": {},
   "source": [
    "Ok, super, il donne quoi cet estimateur pour notre problème ? En quoi ça consiste ? À votre avis ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d1102",
   "metadata": {},
   "source": [
    "Et bien imaginons qu'on veuille déterminer la probabilité d'une phrase, par exemple « le petit chat\n",
    "est content ».\n",
    "\n",
    "- On prend un gros corpus (c'est notre échantillon).\n",
    "- On regarde combien de fois cette phrase apparaît.\n",
    "- Et on divise par la taille du corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915f1b08",
   "metadata": {},
   "source": [
    "Voyons ce que ça donne :\n",
    "\n",
    "- [Combien de pages sur Google pour cette\n",
    "  requête](https://www.google.com/search?q=%22le+petit+chat+est+content%22).\n",
    "- Combien de pages au total dans l'index de Google ? Dur à savoir, mais probablement de l'ordre de\n",
    "  grandeur de $100 000 000 000$.\n",
    "\n",
    "On estimerait alors la probabilité de cette phrase à $0.00000000008$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63fee5c",
   "metadata": {},
   "source": [
    "Ok, parfait, on a fini ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5f2281",
   "metadata": {},
   "source": [
    "C'est quoi la probabilité de « je reconnais l'existence du kiwi-fruit » alors ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840101c9",
   "metadata": {},
   "source": [
    "<https://www.google.com/search?q=%22je+reconnais+l'existence+du+kiwi-fruit%22>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd785bd",
   "metadata": {},
   "source": [
    "Alors ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43aeefa",
   "metadata": {},
   "source": [
    "$0$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3af0168",
   "metadata": {},
   "source": [
    "Mais « Vous désastre réjouirez de que ce aucun ». Ça serait zéro aussi alors ? Est-ce que vraiment\n",
    "on veut mettre la même probabilité à ces deux phrases ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd7ad51",
   "metadata": {},
   "source": [
    "Oups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3061b577",
   "metadata": {},
   "source": [
    "Le problème c'est que l'échantillon qu'il nous faudrait ce n'est pas un échantillon de tout ce qui a\n",
    "déjà été produit comme phrase, mais un échantillon de tout ce qui **pourrait** être produit. Et\n",
    "évidemment ce n'est pas accessible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626c92a1",
   "metadata": {},
   "source": [
    "### Décomposer pour régner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb351d84",
   "metadata": {},
   "source": [
    "Ok, [essayons encore](https://www.youtube.com/watch?v=Xg4Pa3DORCE)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e323b953",
   "metadata": {},
   "source": [
    "Il nous faut une façon plus subtile de procéder. On va se reposer pour ça sur une propriété\n",
    "intéressante du langage humain :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918a8ec",
   "metadata": {},
   "source": [
    "Si je dis : « je suis en train d'écrire sur le… ». Quel est le mot suivant d'après-vous ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b12edde",
   "metadata": {},
   "source": [
    "Il y a évidemment plusieurs solutions. Mais *certaines semblent plus vraisemblables*. 🧐."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e22ec4",
   "metadata": {},
   "source": [
    "Autrement dit : il y a une corrélation (attention, pas un conditionnement total) imposée par le\n",
    "début d'une phrase sur sa suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494e7ee",
   "metadata": {},
   "source": [
    "On va s'appuyer sur ça pour proposer un modèle de langue qui soit **implémentable** (et après ~~on~~\n",
    "vous allez l'implémenter)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e04f2c",
   "metadata": {},
   "source": [
    "On va imaginer un modèle de langue qui fonctionne comme un **processus aléatoire**, c'est-à-dire\n",
    "comme une série de décisions aléatoires. En l'occurrence, on va imaginer un processus où la phrase\n",
    "est générée mot par mot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655aa2ab",
   "metadata": {},
   "source": [
    "Autrement dit :\n",
    "\n",
    "- On choisit le premier mot $w_0$ en regardant pour un corpus échantillon les fréquences des mots\n",
    "  apparaissant en début de phrase.\n",
    "- On choisit le deuxième mot $w_1$ en regardant les fréquences des mots apparaissant en deuxième\n",
    "  position dans les phrases qui commencent par $w_0$.\n",
    "- On choisit $w_2$ en regardant les mots qui apparaissent en troisième position dans les phrases qui\n",
    "  commencent par $w_0, w_1$\n",
    "- …"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10545e45",
   "metadata": {},
   "source": [
    "Les probabilités ici sont plus faciles à estimer :\n",
    "\n",
    "La probabilité $P([w_0, *])$ (qu'on notera aussi $P(w_0)$) qu'un mot apparaisse en début de phrase,\n",
    "c'est\n",
    "\n",
    "\\begin{equation}\n",
    "    P(w_0) = \\frac{\\text{Nombre de phrases qui commencent par $w_0$}}{\\text{Nombre de phrases dans le corpus}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1c6d28",
   "metadata": {},
   "source": [
    "La probabilité $P([w_0, w_1, *]~|~[w_0, *])$, ou $P(w_1|w_0)$ qu'une phrase commence par $w_0, w_1$\n",
    "sachant qu'elle commence par $w_1$ (on parle de probabilité conditionnelle), c'est\n",
    "\n",
    "\\begin{equation}\n",
    "    P(w_0) = \\frac{\\text{Nombre de phrases qui commencent par $w_0, w_1$}}{\\text{Nombre de phrases qui commencent par $w_0$}}\n",
    "\\end{equation}\n",
    "\n",
    "et ainsi de suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1de2944",
   "metadata": {},
   "source": [
    "Et c'est quoi alors la probabilité de la phrase entière ? Et bien, c'est simplement le produit des\n",
    "probabilités, comme quand on suit une série d'expériences avec un arbre (todo dessiner un arbre) :\n",
    "\n",
    "\\begin{equation}\n",
    "    P(w_0, w_1, …, w_n) = P(w_0) × P(w_1|w_0) × P(w_2|w_0, w1) × … × P(w_n | w_0, w_1, …, w_{n-1})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188bb1ca",
   "metadata": {},
   "source": [
    "### N-grammes\n",
    "\n",
    "Évidemment ça ne pouvait pas être si simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473931e9",
   "metadata": {},
   "source": [
    "**Évidemment.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15dc833",
   "metadata": {},
   "source": [
    "Le problème ici, c'est que la procédure itérative qu'on a décrite marche bien en début de phrase,\n",
    "mais en fin de phrase on retombe sur le problème précédent.\n",
    "\n",
    "\\begin{equation}\n",
    "    P(\\text{vert}~|~\\text{Je}, \\text{reconnais}, \\text{l'}, \\text{existence}, \\text{du}, \\text{kiwi-fruit})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f8a3f3",
   "metadata": {},
   "source": [
    "On va donc faire une hypothèse un peu grossière : on va supposer par exemple que \n",
    "\n",
    "\\begin{equation}\n",
    "    P([w_0, w_1, w_2, w_3, *]~|~[w_0, w_1, w_2, *]) = P([w_0, w_1, w_2, w_3, *]~|~[w_1, w_2, *])\n",
    "\\end{equation}\n",
    "\n",
    "Autrement dit la probabilité d'apparition d'un mot ne dépend que des $n$ (ici $3$) mots précédents.\n",
    "Nous donnant ainsi un **modèle de langue à n-grams** (ici trigrammes). Ou plus exactement **une\n",
    "grammaire à n-grams** (mais tout le monde dit modèle de langue, ou *language model*)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a2de3b",
   "metadata": {},
   "source": [
    "## À vous de jouer !\n",
    "\n",
    "Notre objectif ici sera de faire de la **génération de textes**.\n",
    "\n",
    "Pour les données on va d'abord travailler avec [Le Ventre de\n",
    "Paris](../../data/zola_ventre-de-paris.txt) qui est déjà dans ce repo pour les tests puis avec [le\n",
    "corpus CIDRE](https://www.ortolang.fr/market/corpora/cidre) pour passer à l'échelle, mais on\n",
    "pourrait aussi utiliser Wikipedia (par exemple en utilisant\n",
    "[WikiExtractor](https://github.com/attardi/wikiextractor)) ou [OSCAR](https://oscar-corpus.com/).\n",
    "\n",
    "On va devoir faire les choses suivantes (pour un modèle à bigrammes)\n",
    "\n",
    "- Extraire les unigrammes et les bigrammes d'un corpus\n",
    "- Calculer les probas normalisées des bigrammes\n",
    "- Sampler des phrases à partir du modèle\n",
    "\n",
    "On va essayer de faire les choses à la main, sans trop utiliser de bibliothèques, pour bien\n",
    "comprendre ce qui se passe.\n",
    "\n",
    "Puis on étendra à des trigrammes et des n-grammes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fae051a",
   "metadata": {},
   "source": [
    "## ✂️ Tokenization ✂️\n",
    "\n",
    "1\\. Écrire une fonction `crude_tokenizer` qui prend comme argument une chaine de caractères et\n",
    "    renvoie la liste des mots de cette chaîne en séparant sur les espaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "2651aaec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Je', 'reconnais', \"l'existence\", 'du', 'kiwi-fruit.']"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def crude_tokenizer(s):\n",
    "    return s.split()\n",
    "\n",
    "# assert crude_tokenizer(\"Je reconnais l'existence du kiwi-fruit.\") == [\n",
    "#    'Je', 'reconnais', \"l'existence\", 'du', 'kiwi-fruit.']\n",
    "\n",
    "crude_tokenizer(\"Je reconnais l'existence du kiwi-fruit.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68717b",
   "metadata": {},
   "source": [
    "2\\. Modifier la fonction `crude_tokenizer` pour qu'elle sépare aussi suivant les caractères\n",
    "   non alphanumériques. **Indice** ça peut être utile de revoir [la doc sur les expressions\n",
    "   régulières](https://docs.python.org/3/library/re.html) ou de relire [un tuto à ce\n",
    "   sujet](https://realpython.com/regex-python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "598ac83a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Je', 'reconnais', 'l', 'existence', 'du', 'kiwi', 'fruit']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "def crude_tokenizer(s):\n",
    "    \n",
    "    # ss = re.split(r\"'|-| \", s)\n",
    "\n",
    "    # ss = re.split(r\"['.-]\", s)\n",
    "    # print(ss)\n",
    "\n",
    "    \n",
    "    tt = []\n",
    "    ss = re.split(\"\\s|\\W\", s.strip())\n",
    "    for w in ss:\n",
    "        if w:\n",
    "            tt.append(w)\n",
    "    return tt\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# assert crude_tokenizer(\"Je reconnais l'existence du kiwi-fruit.\") == [\n",
    "#    'Je', 'reconnais', 'l', 'existence', 'du', 'kiwi', 'fruit']\n",
    "\n",
    "crude_tokenizer(\"Je reconnais l'existence du kiwi-fruit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762451a",
   "metadata": {},
   "source": [
    "3\\. On aimerait maintenant garder les apostrophes à la fin du mot qui les précède, ainsi que les\n",
    "mots composés ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "5f460681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Je', 'reconnais', \"l'\", 'existence', 'du', 'kiwi-fruit']"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re \n",
    "def crude_tokenizer(s):\n",
    "    # ss = re.split(r\"'| \", s)\n",
    "    # print(ss)\n",
    "\n",
    "    # return re.findall(r\"\\w+(?:'|(?:-\\w+))?\", s)\n",
    "\n",
    "    return re.findall(r\"\\w+(?:'|(?:-)\\w+)?\", s)\n",
    "    \n",
    "\n",
    "\n",
    "# assert crude_tokenizer(\"Je reconnais l'existence du kiwi-fruit.\") == [\n",
    "#    'Je', 'reconnais', \"l'\", 'existence', 'du', 'kiwi-fruit']\n",
    "\n",
    "crude_tokenizer(\"Je reconnais l'existence du kiwi-fruit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f6e1f",
   "metadata": {},
   "source": [
    "4\\. Écrire une fonction `crude_tokenizer_and_normalizer` qui en plus de tokenizer comme précédemment\n",
    "met tous les mots en minuscules\n",
    "\n",
    "On peut évidemment copier-coller le code au-dessus, mais on peut aussi réutiliser ce qu'on a déjà\n",
    "défini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f3ac6b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['je', 'reconnais', \"l'\", 'existence', 'du', 'kiwi-fruit']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def crude_tokenizer_and_normalizer(s):\n",
    "    return re.findall(r\"\\w+(?:'|(?:-)\\w+)?\", s.lower())\n",
    "\n",
    "# asser = crude_tokenizer_and_normalizer(\"Je reconnais l'existence du kiwi-fruit.\") == [\n",
    "#     'je', 'reconnais', \"l'\", 'existence', 'du', 'kiwi-fruit'\n",
    "# ]\n",
    "\n",
    "crude_tokenizer_and_normalizer(\"Je reconnais l'existence du kiwi-fruit.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d0686f",
   "metadata": {},
   "source": [
    "## 💜 Extraire les bigrammes 💜\n",
    "\n",
    "Écrire une fonction `extract_bigrams` qui prend en entrée une liste de mots et renvoie la liste des bigrammes correspondants sous forme de couples de mots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c423218b",
   "metadata": {},
   "source": [
    "Version directe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "392f6191",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('je', 'reconnais'),\n",
       " ('reconnais', \"l'\"),\n",
       " (\"l'\", 'existence'),\n",
       " ('existence', 'du'),\n",
       " ('du', 'kiwi-fruit')]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_bigrams(words):\n",
    "    # return (b for l in words for b in zip(l.split(\" \")[:-1]))\n",
    "\n",
    "    lst = []\n",
    "    for i in range(len(words)-1):   # moins 1 parce qu'on peut pas avoir les bigrams avec les mots (pair 4, 6, etc.)\n",
    "        lst.append((words[i], words[i+1]))  # deux parentheses pour avoir le tuple\n",
    "    return lst\n",
    "\n",
    "\n",
    "# assert extract_bigrams(['je', 'reconnais', \"l'\", 'existence', 'du', 'kiwi-fruit']) == [\n",
    "#     ('je', 'reconnais'),\n",
    "#      ('reconnais', \"l'\"),\n",
    "#      (\"l'\", 'existence'),\n",
    "#      ('existence', 'du'),\n",
    "#      ('du', 'kiwi-fruit')\n",
    "# ]\n",
    "\n",
    "\n",
    "extract_bigrams(['je', 'reconnais', \"l'\", 'existence', 'du', 'kiwi-fruit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01b7858",
   "metadata": {},
   "source": [
    "## 🔢 Compter 🔢"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baba6121",
   "metadata": {},
   "source": [
    "Écrire une fonction `read_corpus` qui prend en argument un chemin vers un fichier texte, l'ouvre, le\n",
    "tokenize et y compte les unigrammes et les bigrammes en renvoyant deux `Counter` associant\n",
    "respectivement à chaque mot et à chaque bigramme leurs nombres d'occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "b5e862f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 5306), ('ã', 4538), ('la', 3565), ('les', 2765), ('il', 2474)]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "    \n",
    "def read_corpus(file_path):\n",
    "    unigrams = Counter()\n",
    "    bigrams = Counter()\n",
    "    \n",
    "    text = open(file_path)\n",
    "    for line in text:\n",
    "        words = crude_tokenizer_and_normalizer(line)\n",
    "        unigrams.update(words)\n",
    "        bigrams.update(extract_bigrams(words))\n",
    "\n",
    "    return unigrams, bigrams\n",
    "\n",
    "\n",
    "unigram_counts, bigram_counts = read_corpus(\"./zola_ventre-de-paris.txt\")\n",
    "\n",
    "# assert unigram_counts.most_common(4) == [('de', 5292), ('la', 3565), ('les', 2746), ('il', 2443)]\n",
    "# assert bigram_counts.most_common(4) == [\n",
    "#     (('de', 'la'), 754),\n",
    "#      ((\"qu'\", 'il'), 424),\n",
    "#      (('à', 'la'), 336),\n",
    "#      ((\"d'\", 'une'), 321)\n",
    "# ]\n",
    "\n",
    "unigram_counts.most_common(5)\n",
    "# bigram_counts.most_common(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecab111e",
   "metadata": {},
   "source": [
    "## 🤓 Estimer les probas 🤓"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e6ee709",
   "metadata": {},
   "source": [
    "On va ensuite estimer les probabilités de transition, c'est-à-dire la probabilité de générer un\n",
    "certain mot $w_1$ sachant que le mot précédent est $w_0$. On le fait en utilisant la formule du\n",
    "maximum de vraisemblance :\n",
    "\n",
    "\\begin{equation}\n",
    "   P(w_1|w_0) := P\\!\\left([w_0, w_1]~|~[w_0, *]\\right) = \\frac{\\text{nombre d'occurrences du bigramme $w_0 w_1$}}{\\text{nombre d'occurrences de l'unigramme $w_0$}}\n",
    "\\end{equation}\n",
    "\n",
    "Pour que ce soit plus agréable à sampler on va utiliser un dictionnaire de dictionnaires :\n",
    "`probs[v][w]` stockera $P(w|v)$.\n",
    "\n",
    "À vous de jouer : écrire une fonction `get_probs`, qui prend en entrée les compteurs de bigrammes\n",
    "et d'unigrammes et renvoie le dictionnaire `probs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce13249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_probs(unigram_counts, bigram_counts):\n",
    "    pass # À toi de coder\n",
    "\n",
    "probs = get_probs(unigram_counts, bigram_counts)\n",
    "\n",
    "# assert probs[\"je\"][\"déjeune\"] == 0.002232142857142857\n",
    "\n",
    "\n",
    "probs[\"je\"][\"déjeune\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed53c1ee",
   "metadata": {},
   "source": [
    "**Astuce** on peut utilise un `defaultdict`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e81ee6",
   "metadata": {},
   "source": [
    "## 🤔 Générer 🤔\n",
    "\n",
    "Pour l'instant on ne va pas se préoccuper de sauvegarder le modèle on va l'utiliser directement pour\n",
    "sampler. Le principe est simple : on choisit le premier mot, puis on choisit le deuxième mot en\n",
    "prenant en compte celui qu'on vient de générer (le premier donc si vous suivez) et ainsi de suite."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f42a5d",
   "metadata": {},
   "source": [
    "**Questions**\n",
    "\n",
    "- Comment on choisit le premier mot ?\n",
    "- Et quand est-ce qu'on décide de s'arrêter ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75afea2",
   "metadata": {},
   "source": [
    "Jurafsky et Martin nous disent\n",
    "\n",
    ">  We’ll first need to augment each sentence with a special symbol `<s>` at the beginning of the\n",
    "> sentence, to give us the bigram context of the first word. We’ll also need a special end-symbol.\n",
    "> `</s>`\n",
    "\n",
    "Heureusement on a un fichier bien fait : il y a une seule phrase par ligne."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0ac608",
   "metadata": {},
   "source": [
    "1\\. Modifier `read_corpus` pour ajouter à la volée `<s>` au début de chaque ligne et `</s>` à la fin\n",
    "de chaque ligne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d11860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(file_path):\n",
    "    pass # À toi de coder\n",
    "    \n",
    "    return unigrams, bigrams\n",
    "\n",
    "\n",
    "unigram_counts, bigram_counts = read_corpus(\"data/zola_ventre-de-paris.txt\")\n",
    "\n",
    "assert unigram_counts.most_common(4) == [('<s>', 8945), ('</s>', 8945), ('de', 5292), ('la', 3565)]\n",
    "assert bigram_counts.most_common(4) == [\n",
    "    (('<s>', '</s>'), 1811),\n",
    "    (('<s>', 'il'), 775),\n",
    "    (('de', 'la'), 754),\n",
    "    (('<s>', 'elle'), 576)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c4814c",
   "metadata": {},
   "source": [
    "Il y a encore un petit problème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a7c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_counts.most_common(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9333bdad",
   "metadata": {},
   "source": [
    "🤔"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6d5c40",
   "metadata": {},
   "source": [
    "On a compté les lignes vides 😤. Ça ne posait pas de problème jusque-là puisque ça n'ajoutait rien\n",
    "aux compteurs de n-grammes, mais maintenant ça nous fait des `[\"<s>\", \"</s>\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af85252",
   "metadata": {},
   "source": [
    "2\\. Modifier `read_corpus` pour ignorer les lignes vides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecb090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(file_path):\n",
    "    pass # À toi de coder\n",
    "\n",
    "\n",
    "unigram_counts, bigram_counts = read_corpus(\"data/zola_ventre-de-paris.txt\")\n",
    "\n",
    "assert unigram_counts.most_common(4) == [('<s>', 7145), ('</s>', 7145), ('de', 5292), ('la', 3565)]\n",
    "assert bigram_counts.most_common(4) == [\n",
    "    (('<s>', 'il'), 775),\n",
    "    (('de', 'la'), 754),\n",
    "    (('<s>', 'elle'), 576),\n",
    "    ((\"qu'\", 'il'), 424)\n",
    "]\n",
    "\n",
    "probs = get_probs(unigram_counts, bigram_counts)\n",
    "assert probs[\"<s>\"][\"le\"] == 0.0298110566829951"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4af847",
   "metadata": {},
   "source": [
    "## 😌 Générer pour de vrai 😌\n",
    "\n",
    "**Bon c'est bon maintenant ?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57ec229",
   "metadata": {},
   "source": [
    "À peu près. On va pouvoir sampler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c21e888",
   "metadata": {},
   "source": [
    "Pour ça on va piocher dans le module [`random`](https://docs.python.org/3/library/random.html) de la\n",
    "bibliothèque standard, et en particulier la fonction\n",
    "[`random.choices`](https://docs.python.org/3/library/random.html#random.choices) qui permet de tirer\n",
    "au sort dans une population finie en précisant les probabilités de chacun de éléments. Le poids\n",
    "n'ont en principe pas besoin d'être normalisés (mais ils le seront ici, évidemment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07934744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02c8a58",
   "metadata": {},
   "source": [
    "Voici par exemple comment choisir un mot qui suivrait « je » :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95d3830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les candidats mots qui peuvent suivre « je »\n",
    "candidates = list(probs[\"je\"].keys())\n",
    "# Leurs poids, ce sont les probabilités qu'on a déjà calculé\n",
    "weights = [probs[\"je\"][c] for c in candidates] \n",
    "random.choices(candidates, weights, k=1)[0]  # Attention `choices` renvoit une liste"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918aa0a",
   "metadata": {},
   "source": [
    "Écrire une fonction `sample` qui prend en argument les probabilités de bigrammes (sous la forme d'un\n",
    "dictionnaire de dictionnaires comme notre `prob`) et génère une phrase en partant de `<s>` et en\n",
    "ajoutant des mots itérativement, s'arrêtant quand `</s>` a été choisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca751cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(bigram_probs):\n",
    "    pass # À toi de coder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16933a3d",
   "metadata": {},
   "source": [
    "Pas de assert ici comme on a de l'aléatoire, mais la cellule suivante permet de tester si ça marche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08052051",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sample(probs))\n",
    "print(\" \".join(sample(probs)[1:-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d02dc5",
   "metadata": {},
   "source": [
    "C'est rigolo, hein ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a0b9d2",
   "metadata": {},
   "source": [
    "Qu'est-ce que vous pensez des textes qu'on génère ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3ee20cd",
   "metadata": {},
   "source": [
    "## 🧐 Aller plus loin 🧐"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbeb4eb",
   "metadata": {},
   "source": [
    "En vous inspirant de ce qui a été fait, coder un générateur de phrases à partir de trigrammes,\n",
    "tétragrammes (4), puis de n-grammes arbitraires."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,md",
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "ca9a115054207d2797d1b78f16e1bfbf4323fc9a87b54d9e455f876acde93457"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
